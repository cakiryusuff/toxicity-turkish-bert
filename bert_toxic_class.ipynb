{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNq0MKwTpR_I"
   },
   "source": [
    "# BERT TRAINING WITH PYTORCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsPaxGUYoZNz"
   },
   "source": [
    "## Required Libraries and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re # Regular expressions for text cleaning (use cautiously with BERT)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, hamming_loss, accuracy_score # Accuracy is less informative for multi-label\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED) # if using CUDA\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "MODEL_NAME = 'dbmdz/bert-base-turkish-cased'\n",
    "MAX_LENGTH = 128 # Max sequence length BERT can handle (adjust based on EDA)\n",
    "BATCH_SIZE = 16 # Adjust based on GPU memory\n",
    "EPOCHS = 3 # Number of training epochs (BERT fine-tuning usually requires few epochs)\n",
    "LEARNING_RATE = 2e-5 # Common learning rate for BERT fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuySsJ1poLIB"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/Overfit-GM/turkish-toxic-language/turkish_toxic_language.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 77800,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 77800,\n        \"samples\": [\n          \"Amina kodumunun hayvan\\u0131 sakatlicak aq\",\n          \"Kazansalarda bu zam olacakd\\u0131 hayatlar\\u0131 yalan bu g\\u00fcne kadar kazand\\u0131klar\\u0131 halde hangi dediklerini yapt\\u0131lar yanda\\u015f midesi doyurmaktan ba\\u015fka\",\n          \"Pozisyon penalt\\u0131 ilk m\\u00fcdahele ayaklar\\u0131na yap\\u0131yor dengesini bozunca ndiayrnin sonra topa eliyle \\u00e7\\u0131karmaya \\u00e7al\\u0131\\u015f\\u0131yor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"PROFANITY\",\n          \"SEXIST\",\n          \"OTHER\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"told\",\n          \"offenseval\",\n          \"bully\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_toxic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-71b0f8c6-b5c7-4fd5-864b-a45d561e1731\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "      <th>is_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phil Spector bir lanet katil olduğunu Biliyors...</td>\n",
       "      <td>INSULT</td>\n",
       "      <td>jigsaw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lan siktirin gidin AMK pozitif sik kafaları Ül...</td>\n",
       "      <td>PROFANITY</td>\n",
       "      <td>told</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2pac Olmak İstiyorum Ja Rule bir Tupac Shakur ...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>jigsaw</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ne yapılması gerekiyor Aradan sonra bu sayfaya...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>jigsaw</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kabul Dream Chaser programı ile ilgili olmayan...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>jigsaw</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71b0f8c6-b5c7-4fd5-864b-a45d561e1731')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-71b0f8c6-b5c7-4fd5-864b-a45d561e1731 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-71b0f8c6-b5c7-4fd5-864b-a45d561e1731');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-7b827a41-d949-4a2e-b6f3-a4a8740ae472\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b827a41-d949-4a2e-b6f3-a4a8740ae472')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-7b827a41-d949-4a2e-b6f3-a4a8740ae472 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                text     target  source  \\\n",
       "0  Phil Spector bir lanet katil olduğunu Biliyors...     INSULT  jigsaw   \n",
       "1  Lan siktirin gidin AMK pozitif sik kafaları Ül...  PROFANITY    told   \n",
       "2  2pac Olmak İstiyorum Ja Rule bir Tupac Shakur ...      OTHER  jigsaw   \n",
       "3  Ne yapılması gerekiyor Aradan sonra bu sayfaya...      OTHER  jigsaw   \n",
       "4  Kabul Dream Chaser programı ile ilgili olmayan...      OTHER  jigsaw   \n",
       "\n",
       "   is_toxic  \n",
       "0         1  \n",
       "1         1  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_toxic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "is_toxic\n",
       "1    40137\n",
       "0    37663\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"is_toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " text_length Statistics (Words):\n",
      "count    77800.000000\n",
      "mean        28.391118\n",
      "std         54.763483\n",
      "min          1.000000\n",
      "25%          8.000000\n",
      "50%         15.000000\n",
      "75%         29.000000\n",
      "max       1215.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['text_length'] = df['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['text_length'], bins=100, kde=True)\n",
    "plt.title('Distribution of Comment Length (Words)')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Frequency')\n",
    "# Limit x-axis for better visualization if needed\n",
    "plt.xlim(0, 500)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n text_length Statistics (Words):\")\n",
    "print(df['text_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    # Remove URLs (optional, BERT might handle some context)\n",
    "    # text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Basic handling of common issues if needed\n",
    "    # text = text.lower() # BERT uncased models handle this\n",
    "    return text\n",
    "\n",
    "# Apply cleaning (demonstrative - may skip depending on BERT variant)\n",
    "# train_df['comment_text_cleaned'] = train_df['comment_text'].apply(clean_text)\n",
    "# test_df['comment_text_cleaned'] = test_df['comment_text'].apply(clean_text)\n",
    "# Use original text for now as BERT benefits from closer-to-raw text\n",
    "df['text_cleaned'] = df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYl8gOG6ofor"
   },
   "source": [
    "## Tokenizer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Tokenization:\n",
      "Text: hepinize merhabalar arkadaşlar nasılsınız?\n",
      "Tokens: ['[CLS]', 'hepinize', 'merhabalar', 'arkadaşlar', 'nasıl', '##sınız', '?', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "Input IDs: tensor([[    2, 28015, 28660,  7208,  2767,  3342,    35,     3,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Example tokenization\n",
    "sample_text = \"hepinize merhabalar arkadaşlar nasılsınız?\"\n",
    "tokens = tokenizer.encode_plus(\n",
    "    sample_text,\n",
    "    max_length=32,\n",
    "    padding='max_length', # Pad to max_length\n",
    "    truncation=True,      # Truncate longer sequences\n",
    "    return_tensors='pt'   # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "print(\"\\nSample Tokenization:\")\n",
    "print(f\"Text: {sample_text}\")\n",
    "print(f\"Tokens: {tokenizer.convert_ids_to_tokens(tokens['input_ids'][0])}\")\n",
    "print(f\"Input IDs: {tokens['input_ids']}\")\n",
    "print(f\"Attention Mask: {tokens['attention_mask']}\") # 1 for real tokens, 0 for padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p23kLk3SpjiD"
   },
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train size: 70020, Validation size: 7780\n",
      "\n",
      "Sample batch shapes:\n",
      "Input IDs: torch.Size([16, 128])\n",
      "Attention Mask: torch.Size([16, 128])\n",
      "Labels: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "class ToxicCommentDataset(Dataset):\n",
    "    def __init__(self, comments, labels, tokenizer, max_len):\n",
    "        self.comments = comments\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        comment = str(self.comments[item])\n",
    "        target = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            comment,\n",
    "            add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False, # Not needed for basic BERT classification\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt', # Return PyTorch tensors\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'comment_text': comment,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(target, dtype=torch.float) # Use float for BCEWithLogitsLoss\n",
    "        }\n",
    "\n",
    "X = df['text'].values\n",
    "y = df['is_toxic'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.1, # Use 10% for validation\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain size: {len(X_train)}, Validation size: {len(X_val)}\")\n",
    "\n",
    "train_dataset = ToxicCommentDataset(X_train, y_train, tokenizer, MAX_LENGTH)\n",
    "val_dataset = ToxicCommentDataset(X_val, y_val, tokenizer, MAX_LENGTH)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2) # num_workers depends on your system\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "data = next(iter(train_dataloader))\n",
    "print(\"\\nSample batch shapes:\")\n",
    "print(\"Input IDs:\", data['input_ids'].shape)\n",
    "print(\"Attention Mask:\", data['attention_mask'].shape)\n",
    "print(\"Labels:\", data['labels'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgOnSG0rpsqr"
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, configuring it for multi-label\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=1, # Number of output labels = number of toxic categories\n",
    "    output_attentions=False, # Optional: set to True if you want attention weights\n",
    "    output_hidden_states=False, # Optional: set to True if you want hidden states\n",
    ")\n",
    "\n",
    "# Move the model to the designated device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "print(\"\\nModel loaded successfully.\")\n",
    "# print(model) # Uncomment to see model architecture details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 110618113\n",
      "Trainable parameter count: 110618113\n"
     ]
    }
   ],
   "source": [
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "total = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameter count: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcnBY1m8p7Lv"
   },
   "source": [
    "## Optimizer, Loss, Scheduler Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=1e-8)\n",
    "\n",
    "# Total number of training steps\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0, # Optional: set a number of warmup steps (e.g., 0.1 * total_steps)\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Loss function for multi-label classification\n",
    "# BCEWithLogitsLoss combines a Sigmoid layer and Binary Cross Entropy loss in one class.\n",
    "# It's numerically more stable than using a plain Sigmoid followed by BCE Loss.\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1phCzFLqRhF"
   },
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = len(data_loader)\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        # Move batch to device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Clear previous gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        logits = outputs.logits # Raw model output (before sigmoid)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(logits, labels.unsqueeze(1))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients to prevent exploding gradients (common practice)\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        scheduler.step() # Update learning rate\n",
    "\n",
    "        # Print progress (optional)\n",
    "        if (i + 1) % 1000 == 0:\n",
    "             print(f'  Batch {i + 1}/{num_batches} | Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "    avg_train_loss = total_loss / num_batches\n",
    "    print(f\"\\n  Average Training Loss: {avg_train_loss:.4f}\")\n",
    "    return avg_train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyCd01wuqTYA"
   },
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device):\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    num_batches = len(data_loader)\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculation\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = loss_fn(logits, labels.unsqueeze(1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.sigmoid(logits)\n",
    "            all_preds.append(probs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_loss / num_batches\n",
    "    print(f\"  Average Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    roc_auc_scores = {}\n",
    "    mean_roc_auc = 0\n",
    "    try:\n",
    "        for i in range(all_preds.shape[1]):\n",
    "            roc_auc = roc_auc_score(all_labels[:, i], all_preds[:, i])\n",
    "            roc_auc_scores[f\"Label {i}\"] = roc_auc\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Could not calculate ROC AUC: {e}\")\n",
    "\n",
    "    threshold = 0.5\n",
    "    binary_preds = (all_preds > threshold).astype(int)\n",
    "    hamming = hamming_loss(all_labels, binary_preds)\n",
    "    print(f\"  Hamming Loss: {hamming:.4f}\")\n",
    "\n",
    "    # (Optional) You can also calculate Micro/Macro F1 scores or Accuracy (less useful)\n",
    "    # print(\"\\nClassification Report (threshold=0.5):\")\n",
    "    # print(classification_report(all_labels, binary_preds, target_names=label_cols, zero_division=0))\n",
    "\n",
    "    return avg_val_loss, mean_roc_auc, hamming # Return key metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CM7djTsrW6i"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n",
      "\n",
      "--- Epoch 1/3 ---\n",
      "  Batch 100/4377 | Loss: 0.2311\n",
      "  Batch 200/4377 | Loss: 0.2501\n",
      "  Batch 300/4377 | Loss: 0.0745\n",
      "  Batch 400/4377 | Loss: 0.1351\n",
      "  Batch 500/4377 | Loss: 0.1678\n",
      "  Batch 600/4377 | Loss: 0.2320\n",
      "  Batch 700/4377 | Loss: 0.0117\n",
      "  Batch 800/4377 | Loss: 0.0018\n",
      "  Batch 900/4377 | Loss: 0.2737\n",
      "  Batch 1000/4377 | Loss: 0.0970\n",
      "  Batch 1100/4377 | Loss: 0.0243\n",
      "  Batch 1200/4377 | Loss: 0.1397\n",
      "  Batch 1300/4377 | Loss: 0.3009\n",
      "  Batch 1400/4377 | Loss: 0.0286\n",
      "  Batch 1500/4377 | Loss: 0.2805\n",
      "  Batch 1600/4377 | Loss: 0.0050\n",
      "  Batch 1700/4377 | Loss: 0.1498\n",
      "  Batch 1800/4377 | Loss: 0.0016\n",
      "  Batch 1900/4377 | Loss: 0.0646\n",
      "  Batch 2000/4377 | Loss: 0.0081\n",
      "  Batch 2100/4377 | Loss: 0.0032\n",
      "  Batch 2200/4377 | Loss: 0.0026\n",
      "  Batch 2300/4377 | Loss: 0.2876\n",
      "  Batch 2400/4377 | Loss: 0.0112\n",
      "  Batch 2500/4377 | Loss: 0.0318\n",
      "  Batch 2600/4377 | Loss: 0.0029\n",
      "  Batch 2700/4377 | Loss: 0.0023\n",
      "  Batch 2800/4377 | Loss: 0.1752\n",
      "  Batch 2900/4377 | Loss: 0.1712\n",
      "  Batch 3000/4377 | Loss: 0.1884\n",
      "  Batch 3100/4377 | Loss: 0.0046\n",
      "  Batch 3200/4377 | Loss: 0.0026\n",
      "  Batch 3300/4377 | Loss: 0.2236\n",
      "  Batch 3400/4377 | Loss: 0.2034\n",
      "  Batch 3500/4377 | Loss: 0.0053\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-73-2215250096.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\n--- Epoch {epoch + 1}/{EPOCHS} ---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     train_loss = train_epoch(\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-71-3953147048.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, device, scheduler)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Clip gradients to prevent exploding gradients (common practice)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36m_no_grad_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_no_grad_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_no_grad_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# prevent generators from being exhausted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mparameters\u001b[0;34m(self, recurse)\u001b[0m\n\u001b[1;32m   2628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m         \"\"\"\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_parameters\u001b[0;34m(self, prefix, recurse, remove_duplicate)\u001b[0m\n\u001b[1;32m   2661\u001b[0m             \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_duplicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2662\u001b[0m         )\n\u001b[0;32m-> 2663\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_named_members\u001b[0;34m(self, get_members_fn, prefix, recurse, remove_duplicate)\u001b[0m\n\u001b[1;32m   2602\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2603\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2604\u001b[0;31m                     \u001b[0mmemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2605\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmodule_prefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m         \u001b[0;31m# Do NOT handle __torch_function__ here as user's default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;31m# implementation that handle most functions will most likely do it wrong.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = {'train_loss': [], 'val_loss': [], 'val_roc_auc': [], 'val_hamming': []}\n",
    "best_roc_auc = -1\n",
    "best_model_state = None\n",
    "\n",
    "print(\"\\nStarting Training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\\n--- Epoch {epoch + 1}/{EPOCHS} ---')\n",
    "\n",
    "    train_loss = train_epoch(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler\n",
    "    )\n",
    "    history['train_loss'].append(train_loss)\n",
    "\n",
    "    print(f\"\\n--- Validation Epoch {epoch + 1} ---\")\n",
    "    val_loss, val_roc_auc, val_hamming = eval_model(\n",
    "        model,\n",
    "        val_dataloader,\n",
    "        loss_fn,\n",
    "        device\n",
    "    )\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_roc_auc'].append(val_roc_auc)\n",
    "    history['val_hamming'].append(val_hamming)\n",
    "\n",
    "    # Save the best model based on validation ROC AUC\n",
    "    if val_roc_auc > best_roc_auc:\n",
    "        best_roc_auc = val_roc_auc\n",
    "        best_model_state = model.state_dict()\n",
    "        torch.save(best_model_state, 'best_model_state.bin')\n",
    "        print(f\"  ** New best model saved with ROC AUC: {best_roc_auc:.4f} **\")\n",
    "\n",
    "print(\"\\nTraining Finished.\")\n",
    "print(f\"Best Validation ROC AUC: {best_roc_auc:.4f}\")\n",
    "\n",
    "# Load the best model state for prediction\n",
    "if best_model_state:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"Loaded best model state for prediction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9bCttfHrbZC"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: 10.020668029785156\n",
      "Olasılık (toksik olma ihtimali): 0.9999555349349976\n",
      "Tahmin edilen sınıf: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "text = \"kötü kokuyorsun.\"\n",
    "\n",
    "encoding = tokenizer.encode_plus(\n",
    "    text,\n",
    "    add_special_tokens=True,\n",
    "    max_length=MAX_LENGTH,\n",
    "    return_token_type_ids=False,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids = encoding['input_ids'].to(device)\n",
    "attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = output.logits\n",
    "    probs = torch.sigmoid(logits)\n",
    "\n",
    "print(\"Logits:\", logits.item())\n",
    "print(\"Olasılık (toksik olma ihtimali):\", probs.item())\n",
    "\n",
    "threshold = 0.5\n",
    "predicted_label = int(probs.item() > threshold)\n",
    "print(\"Tahmin edilen sınıf:\", predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3mpP7ErxEmV"
   },
   "source": [
    "# BERT TRAINING WITH HUGGINGFACE TRAINER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqAKV-67sDos"
   },
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/Overfit-GM/turkish-toxic-language/turkish_toxic_language.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 77800,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 77800,\n        \"samples\": [\n          \"Amina kodumunun hayvan\\u0131 sakatlicak aq\",\n          \"Kazansalarda bu zam olacakd\\u0131 hayatlar\\u0131 yalan bu g\\u00fcne kadar kazand\\u0131klar\\u0131 halde hangi dediklerini yapt\\u0131lar yanda\\u015f midesi doyurmaktan ba\\u015fka\",\n          \"Pozisyon penalt\\u0131 ilk m\\u00fcdahele ayaklar\\u0131na yap\\u0131yor dengesini bozunca ndiayrnin sonra topa eliyle \\u00e7\\u0131karmaya \\u00e7al\\u0131\\u015f\\u0131yor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"PROFANITY\",\n          \"SEXIST\",\n          \"OTHER\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"told\",\n          \"offenseval\",\n          \"bully\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_toxic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-6a5c9f2c-5b30-4e6b-8cc9-122a27affca5\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "      <th>is_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phil Spector bir lanet katil olduğunu Biliyors...</td>\n",
       "      <td>INSULT</td>\n",
       "      <td>jigsaw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lan siktirin gidin AMK pozitif sik kafaları Ül...</td>\n",
       "      <td>PROFANITY</td>\n",
       "      <td>told</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2pac Olmak İstiyorum Ja Rule bir Tupac Shakur ...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>jigsaw</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ne yapılması gerekiyor Aradan sonra bu sayfaya...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>jigsaw</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kabul Dream Chaser programı ile ilgili olmayan...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>jigsaw</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a5c9f2c-5b30-4e6b-8cc9-122a27affca5')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6a5c9f2c-5b30-4e6b-8cc9-122a27affca5 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6a5c9f2c-5b30-4e6b-8cc9-122a27affca5');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-9c095d11-731f-4c13-886a-43d10eb22e01\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c095d11-731f-4c13-886a-43d10eb22e01')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-9c095d11-731f-4c13-886a-43d10eb22e01 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                text     target  source  \\\n",
       "0  Phil Spector bir lanet katil olduğunu Biliyors...     INSULT  jigsaw   \n",
       "1  Lan siktirin gidin AMK pozitif sik kafaları Ül...  PROFANITY    told   \n",
       "2  2pac Olmak İstiyorum Ja Rule bir Tupac Shakur ...      OTHER  jigsaw   \n",
       "3  Ne yapılması gerekiyor Aradan sonra bu sayfaya...      OTHER  jigsaw   \n",
       "4  Kabul Dream Chaser programı ile ilgili olmayan...      OTHER  jigsaw   \n",
       "\n",
       "   is_toxic  \n",
       "0         1  \n",
       "1         1  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_toxic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "is_toxic\n",
       "1    40137\n",
       "0    37663\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_0 = df[df['is_toxic'] == 0]\n",
    "df_1 = df[df['is_toxic'] == 1]\n",
    "\n",
    "min_count = min(len(df_0), len(df_1))\n",
    "\n",
    "df_0_downsampled = resample(df_0, replace=False, n_samples=min_count, random_state=42)\n",
    "df_1_downsampled = resample(df_1, replace=False, n_samples=min_count, random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([df_0_downsampled, df_1_downsampled])\n",
    "\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_balanced.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 75326,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 75326,\n        \"samples\": [\n          \"Erkek erke\\u011fe birbirini kullananlar \\u0130stanbul s\\u00f6zle\\u015fmesi deyip bir de y\\u00fcr\\u00fcy\\u00fc\\u015f yap\\u0131p Ad\\u0131na da onur y\\u00fcr\\u00fcy\\u00fc\\u015f\\u00fc diyorlar La gavur o\\u011flu gavurlar sizde onur ne gezer a\\u015fa\\u011f\\u0131l\\u0131k maymunlar \\u0130\\u015fte anlayana en kolay yoldan istanbul s\\u00f6zle\\u015fmesi budur\",\n          \"CQ makalesini okurken NYT de\\u011fildi durum \\u00e7o\\u011funlukla \\u00e7\\u00f6z\\u00fclm\\u00fc\\u015f gibi okuyor\",\n          \"asla T\\u00fcm mesajlar\\u0131n\\u0131z\\u0131 okumadan sildim sen hasta ve ac\\u0131mas\\u0131z bir insans\\u0131n Seni bir daha konu\\u015fma sayfamda g\\u00f6rmek istemiyorum Endi\\u015felenme e\\u011fer istemiyorsan beni g\\u00f6rmeyeceksin \\u015eimdi g\\u00f6rece\\u011finiz \\u015fey sahip oldu\\u011funuz problemlerdir Onlara girdiniz ve aylar \\u00f6ncesinden beri hala onlar\\u0131n i\\u00e7indesiniz Hakl\\u0131 de\\u011fil miyim Ve onlara hitap ederken yapt\\u0131\\u011f\\u0131n\\u0131z ince bir hata var Ne oldu\\u011funu merak ediyor musunuz Burada olaca\\u011f\\u0131m Hasta ve zalim belki ama bu sadece sade ve ger\\u00e7ek olman\\u0131n bir tezah\\u00fcr\\u00fcd\\u00fcr hayali renkler yok gizli \\u015feyler yok Kutsal sava\\u015f\\u0131n\\u0131zda iyi \\u015fanslar OMG daha \\u00f6nce nas\\u0131l tahmin edemedim Kim oldu\\u011funu biliyorum Dr Jekyll olarak ayr\\u0131ld\\u0131n\\u0131z ve birka\\u00e7 g\\u00fcn sonra Bay Hyde olarak geri d\\u00f6nd\\u00fcn\\u00fcz Ger\\u00e7ekten ger\\u00e7ekten hastas\\u0131n Biraz yard\\u0131m almal\\u0131s\\u0131n Senin i\\u00e7in \\u00fczg\\u00fcn hissediyorum Ger\\u00e7ekten hasta olan ben miyim Olabilir Neyse ki sizin gibi farkl\\u0131 bir hastal\\u0131k Her neyse s\\u00f6ylediklerime bakmak istemiyorsun \\u00e7ok fazla chitchatting yapman\\u0131n anlam\\u0131 yok E\\u011fer ger\\u00e7ekten isimlerimi isimlendirebilirsen bunu yap Yararl\\u0131 ve umrumda de\\u011fil Alison konu\\u015fma sayfas\\u0131nda b\\u0131rakt\\u0131\\u011f\\u0131n\\u0131z mesaja bir yan\\u0131t almak isterseniz l\\u00fctfen oradan kald\\u0131r\\u0131n ve kendi konu\\u015fma sayfan\\u0131za yeniden g\\u00f6nderin Hakl\\u0131 olarak s\\u00f6yledi\\u011fin gibi Alison \\u0131n bana g\\u00f6nderilen mesajla hi\\u00e7bir ilgisi yok ve konu\\u015fma sayfas\\u0131 yaln\\u0131z b\\u0131rak\\u0131lmal\\u0131d\\u0131r Sizden Alison \\u0131n konu\\u015fma sayfas\\u0131ndan silmenizi istedim sadece kopyalad\\u0131n\\u0131z L\\u00fctfen silin oraya ait de\\u011fildir ve konu\\u015faca\\u011f\\u0131z Oraya ait Bu sadece size bir mesaj de\\u011fil ayn\\u0131 zamanda orada bulunan di\\u011fer ikisine de bir mesajd\\u0131r Sadece yar\\u0131da s\\u00f6ylenen bir hikayeyi tamamlad\\u0131\\u011f\\u0131 i\\u00e7in neden olmasayd\\u0131m Burada devam etmeyi s\\u00f6yledim \\u00e7\\u00fcnk\\u00fc gerisi benimle ilgili olacak Ancak oradaki metnin okuyucular i\\u00e7in ipu\\u00e7lar\\u0131 verdi\\u011fine dikkat edin b\\u00f6ylece daha fazla okumak isterse buraya gelece\\u011fini biliyorlar Bu paragraf\\u0131 orada silersem orada sadece bilgi kaybolmaz ayn\\u0131 zamanda burada devam ile ilgili hi\\u00e7bir \\u015fey kaybolmaz ba\\u015fka bir yerden kopyaland\\u0131 Tek ama\\u00e7 Kullan\\u0131c\\u0131 katk\\u0131lar\\u0131ma bak Maalesef tek amac\\u0131m\\u0131n size yard\\u0131m etmek oldu\\u011funu d\\u00fc\\u015f\\u00fcnerek kendinizi \\u00e7ok fazla \\u00f6d\\u00fcllendiriyorsunuz Bu tam tersi \\u015eans eseri sorunlar\\u0131n\\u0131z\\u0131n durmad\\u0131\\u011f\\u0131n\\u0131 fark ettim FPC yi bozmaya bile geldiklerinden Her zaman yapmaya \\u00e7al\\u0131\\u015ft\\u0131\\u011f\\u0131m gibi resimlerinizden birini en ki\\u015filiksiz ve objektif bir \\u015fekilde inceledi\\u011fimde oldu\\u011fu gibi biraz paranoyak oluyorsunuz Sadece g\\u00f6rd\\u00fc\\u011f\\u00fcm \\u015feyler aras\\u0131nda do\\u011fru oldu\\u011funu d\\u00fc\\u015f\\u00fcnd\\u00fc\\u011f\\u00fcmleri destekliyorum Ne olursa olsun \\u0130nsanlar\\u0131n sana yanl\\u0131\\u015f yapt\\u0131\\u011f\\u0131n\\u0131 g\\u00f6r\\u00fcnce k\\u0131nad\\u0131m E\\u011fer yanl\\u0131\\u015f yapt\\u0131\\u011f\\u0131n\\u0131 g\\u00f6r\\u00fcrsem sana s\\u00f6ylerim Ama bir kereden fazla de\\u011fil Yard\\u0131ma ihtiyac\\u0131m oldu\\u011funu s\\u00f6yl\\u00fcyorsun Devam et bana g\\u00f6rd\\u00fc\\u011f\\u00fcn belirtileri s\\u00f6yle Konu\\u015fma sayfamda Alison \\u0131n t\\u00fcm bu yay\\u0131nlardan rahats\\u0131z olmas\\u0131 gerekti\\u011finden Abisharan konu\\u015fma Ortak dillerin t\\u00fcm\\u00fc ba\\u011flama ba\\u011fl\\u0131d\\u0131r Bu mesaj bu yar\\u0131\\u015fmada olan \\u015feydir Bu y\\u00fczden sadece kopyalamaya daha \\u00e7ok inan\\u0131yorum Sen ispanyolsun Edulcorante veya \\u015feker yak\\u0131n edulcorantion dediniz 71 107 144 106 taraf\\u0131ndan eklenen imzas\\u0131z yorum eklendi Yapt\\u0131m \\u0130ngilizce de bir kelime olmas\\u0131na ra\\u011fmen tatl\\u0131l\\u0131k ile ayn\\u0131 anlama gelir Ayr\\u0131ca bir kab\\u0131 su ile durulama eyleminde kullan\\u0131lan kimyager G\\u00fczel bir kelimedir \\u00f6zellikle de daha \\u00f6nceki bir c\\u00fcmlede tatl\\u0131 yani kulland\\u0131ysan\\u0131z Kelimeleri tekrarlaman\\u0131z gerekmedi\\u011finde i\\u015fler daha iyi ses \\u00e7\\u0131kar\\u0131r\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-5567deeb-8e00-4934-9e61-4d52c3ca2cdf\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mea Culpa Bunu işaret ettiğiniz için teşekkürler</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hayır belki değil çünkü eğer denersem davamın ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>İki tosunun resmini görmek isterim¿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Termoplastik Kauçuk Sana daha önce söylemeliyd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bilinen bir gerçeği belirtmek için beni engell...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5567deeb-8e00-4934-9e61-4d52c3ca2cdf')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5567deeb-8e00-4934-9e61-4d52c3ca2cdf button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5567deeb-8e00-4934-9e61-4d52c3ca2cdf');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-59186295-2201-4f07-881c-b922910edb52\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-59186295-2201-4f07-881c-b922910edb52')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-59186295-2201-4f07-881c-b922910edb52 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0   Mea Culpa Bunu işaret ettiğiniz için teşekkürler      0\n",
       "1  Hayır belki değil çünkü eğer denersem davamın ...      0\n",
       "2                İki tosunun resmini görmek isterim¿      0\n",
       "3  Termoplastik Kauçuk Sana daha önce söylemeliyd...      0\n",
       "4  Bilinen bir gerçeği belirtmek için beni engell...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    # text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Harfler dışındaki her şeyi sil (sadece Türkçe ve İngilizce harfleri tut)\n",
    "    text = re.sub(r'[^a-zA-ZçÇğĞıİöÖşŞüÜ\\s]', '', text)\n",
    "\n",
    "    # Birden fazla boşluğu teke indir ve baş/son boşlukları temizle\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "df['text_cleaned'] = df['text']\n",
    "\n",
    "df = df.drop(columns=['text', 'target', \"source\"])\n",
    "df[\"text\"] = df[\"text_cleaned\"]\n",
    "df = df.rename(columns={\"is_toxic\": \"label\"})\n",
    "df = df[[\"text\", \"label\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d1a2aaa8e945f2b007e8a5c129c20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6523cb1ff99d47f5b03e5bfeaa472493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b863ff02d4e4d08b6fefd353a806f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b5bd3ad6fb4f3c8ee3030c572fbeae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75326 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a663bf6aedf4f59b56826e168ff86cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75326 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_dataset = tokenized_dataset.map(lambda x: {\"labels\": float(x[\"labels\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0692efe4a07142c8b778bf8115836720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/75326 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Value\n",
    "tokenized_dataset = tokenized_dataset.cast_column(\"labels\", Value(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = split_dataset['train']\n",
    "eval_dataset = split_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cA3FUBk5xDKv"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbde46d8cbc434c8ef4e385673fa48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.53.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"dbmdz/bert-base-turkish-cased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
    "\n",
    "print(model.config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 110618113\n"
     ]
    }
   ],
   "source": [
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPXg58fB2hvC"
   },
   "source": [
    "custom bert if you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, pretrained_model_name, num_labels):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=num_labels)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = self.dropout(output[1])  # Applying dropout\n",
    "        logits = self.fc(pooled_output)  # Adding a fully connected layer\n",
    "        return logits\n",
    "\n",
    "# Initialize the custom model\n",
    "custom_model = CustomBERTModel(\"dbmdz/bert-base-turkish-cased\", num_labels=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQTucVt5xFjg"
   },
   "source": [
    "## Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.EPOCH,\n",
      "eval_use_gather_object=False,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_revision=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "liger_kernel_config=None,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./logs,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=100,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=f1,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=4,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./results,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard', 'wandb'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./results,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=SaveStrategy.EPOCH,\n",
      "save_total_limit=2,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",           # Directory for saving model checkpoints\n",
    "    eval_strategy=\"epoch\",     # Evaluate at the end of each epoch\n",
    "    # eval_steps=500,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,              # Start with a small learning rate\n",
    "    per_device_train_batch_size=16,  # Batch size per GPU\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,              # Number of epochs\n",
    "    weight_decay=0.01,               # Regularization\n",
    "    save_total_limit=2,              # Limit checkpoints to save space\n",
    "    load_best_model_at_end=True,     # Automatically load the best checkpoint\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_dir=\"./logs\",            # Directory for logs\n",
    "    logging_steps=100,               # Log every 100 steps\n",
    "    fp16=True                        # Enable mixed precision for faster training\n",
    ")\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./bert-binary\",\n",
    "#     eval_strategy=\"steps\",\n",
    "#     eval_steps=50,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     num_train_epochs=5,\n",
    "#     logging_steps=10,\n",
    "#     save_total_limit=2,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"accuracy\",\n",
    "#     greater_is_better=True\n",
    "# )\n",
    "\n",
    "print(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzHbyy3-xInW"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVSwctBPxK8z"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-17-1041615943.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mckryusuff\u001b[0m (\u001b[33mckryusuff-student\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250718_230518-8jafcsjt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ckryusuff-student/huggingface/runs/8jafcsjt' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/ckryusuff-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ckryusuff-student/huggingface' target=\"_blank\">https://wandb.ai/ckryusuff-student/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ckryusuff-student/huggingface/runs/8jafcsjt' target=\"_blank\">https://wandb.ai/ckryusuff-student/huggingface/runs/8jafcsjt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16952' max='16952' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16952/16952 40:32, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.032597</td>\n",
       "      <td>0.505111</td>\n",
       "      <td>0.671194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.033696</td>\n",
       "      <td>0.939068</td>\n",
       "      <td>0.942474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.030285</td>\n",
       "      <td>0.575601</td>\n",
       "      <td>0.704118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.029567</td>\n",
       "      <td>0.957255</td>\n",
       "      <td>0.959054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16952, training_loss=0.027621367878582524, metrics={'train_runtime': 2537.7248, 'train_samples_per_second': 106.856, 'train_steps_per_second': 6.68, 'total_flos': 1.7836927624006656e+16, 'train_loss': 0.027621367878582524, 'epoch': 4.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                        # Pre-trained BERT model\n",
    "    args=training_args,                 # Training arguments\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,        # Efficient batching\n",
    "    compute_metrics=compute_metrics,     # Custom metric\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # Early stopping\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZcFaw1oxNML"
   },
   "source": [
    "## Save to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947e172fc67647b79d95c2000e9601d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b0a53a89a649e3a6910d1879f7d8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865589b6dc62446dad19dd636ab95f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc89bef738b4d238b3ccead8a8f1cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/cakiryusuff/results/commit/c7a5a5ed6ede91207e593af71320c004341479b3', commit_message='turkish-toxic-comment-classifier', commit_description='', oid='c7a5a5ed6ede91207e593af71320c004341479b3', pr_url=None, repo_url=RepoUrl('https://huggingface.co/cakiryusuff/results', endpoint='https://huggingface.co', repo_type='model', repo_id='cakiryusuff/results'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()\n",
    "trainer.push_to_hub(\"turkish-toxic-comment-classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fi-zfgoxQQu"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict(text, threshold=0.6):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Apply sigmoid instead of softmax\n",
    "    probs = torch.sigmoid(logits)\n",
    "\n",
    "    print(probs)\n",
    "    # Convert probabilities to binary predictions using threshold\n",
    "    predictions = (probs > threshold).int()\n",
    "    print(predictions)\n",
    "\n",
    "    # Return prediction indices of classes where prediction == 1\n",
    "    predicted_classes = predictions.squeeze()\n",
    "\n",
    "    return predicted_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7086]], device='cuda:0')\n",
      "tensor([[1]], device='cuda:0', dtype=torch.int32)\n",
      "tensor(1, device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"abi kötü oynuyorsun\"\n",
    "predicted_classes = predict(sample_text)\n",
    "\n",
    "print(predicted_classes)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
